{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Icv-kXx_Slb5"
   },
   "source": [
    "## Wysokopoziomowy interfejs Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cbM5IcviXVrh"
   },
   "source": [
    "### Importy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sQkcv7ohLAyf"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SdPJNdJzrGdO"
   },
   "outputs": [],
   "source": [
    "# Załadowanie rozszerzenia tensorboard\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9SDRIWVHXLrU"
   },
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "print(f\"Dane treningowe: {len(x_train)} próbek\")\n",
    "print(f\"Dane testowe: {len(x_test)} próbek\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CQ0NREioYImu"
   },
   "source": [
    "### Budowanie modelu\n",
    "\n",
    "Keras posiada dwie metody tworzenia modelu sieci neuronowej:\n",
    "* sekwencyjne API (aka model sekwencyjny - tf.keras.models.Sequential)\n",
    "* funkcyjne API\n",
    "\n",
    "Najpierw zdefiniujmy model przy użyciu bardziej popularnego, **sekwencyjnego api**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q2k2wDk8c1jb"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "layer_1 = tf.keras.layers.Flatten(input_shape=(28, 28))\n",
    "layer_2 = tf.keras.layers.Dense(128, activation='relu')\n",
    "layer_3 = tf.keras.layers.Dropout(0.2)  # regularization layer\n",
    "layer_4 = tf.keras.layers.Dense(10, activation='softmax')  # normalization layer\n",
    "\n",
    "model.add(layer_1)\n",
    "model.add(layer_2)\n",
    "model.add(layer_3)\n",
    "model.add(layer_4)\n",
    "\n",
    "\n",
    "# # moglibyśmy to równie dobrze wszystko zmieścić w jednym wywołaniu\n",
    "# model = tf.keras.models.Sequential([\n",
    "#     tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "#     tf.keras.layers.Dense(128, activation='relu'),\n",
    "#     tf.keras.layers.Dropout(0.2),\n",
    "#     tf.keras.layers.Dense(10, activation='softmax')\n",
    "# ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A jak wyglądałoby definiowanie modelu przy użyciu funkcyjnego API ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# warstwę poprzednią przekazujemy do warstwy następującej po niej\n",
    "input_layer = tf.keras.layers.Input(shape=(28, 28))\n",
    "layer_1 = tf.keras.layers.Flatten(input_shape=(28, 28))(input_layer)\n",
    "layer_2 = tf.keras.layers.Dense(128, activation='relu')(layer_1)\n",
    "layer_3 = tf.keras.layers.Dropout(0.2)(layer_2)\n",
    "output_layer = tf.keras.layers.Dense(10, activation='softmax')(layer_3)\n",
    "\n",
    "# i definiujemy model przekazując mu warstwę wejściową oraz warstwę wyjściową\n",
    "model = tf.keras.models.Model(inputs=input_layer, outputs=output_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dhJX0oK9dTOv"
   },
   "source": [
    "Dla każdego przykładu model zwraca wektor wyników [logit](https://developers.google.com/machine-learning/glossary#logits) lub [log-odds](https://developers.google.com/machine-learning/glossary#log-odds) , po jednym dla każdej klasy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JB3iQLmcdnkE"
   },
   "outputs": [],
   "source": [
    "predictions = model(x_train[:1]).numpy()\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZpueTZKIlxlY"
   },
   "source": [
    "### Konfiguracja i kompilacja modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X12AnrOIix-B"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',  # optymalizator adam/SGD\n",
    "    loss='sparse_categorical_crossentropy',  # funkcja strat \n",
    "    metrics=['accuracy']  # metryki\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4CnJCYnljrfy"
   },
   "source": [
    "**adam** (ang. **ada**ptive **m**oment estimation) - optymalizator, można porównać z dodawaniem lub zmniejszaniem przyśpieszenia w zależności od stromizny zbocza podczas poruszania się po pagórkowatym terenie.\n",
    "\n",
    "**sparse_categorical_crossentropy** to funkcja strat równa ujemnemu logarytmicznemu prawdopodobieństwu prawdziwej klasy. Jej wartość wynosi zero, jeśli model jest pewien, że klasa jest prawidłowa.\n",
    "\n",
    "**accuracy** - dokładność modelu (stosunek poprawnych predykcji do całkowitej liczby predykcji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sHguk8a7rTKx"
   },
   "outputs": [],
   "source": [
    "# Tworzenie callbacku na potrzeby tensorboard\n",
    "import datetime\n",
    "\n",
    "log_dir = 'adam_' + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wK1z9wpxl_T8"
   },
   "source": [
    "### Trenowanie modelu razem z walidacją (sprawdzeniem wydajności modelu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CamcJYWlmAqw"
   },
   "outputs": [],
   "source": [
    "r = model.fit(\n",
    "    x_train, \n",
    "    y_train, \n",
    "    validation_data=(x_test, y_test), \n",
    "    epochs=5,\n",
    "    callbacks=[\n",
    "        tensorboard_callback\n",
    "    ]\n",
    ")  # accuracy - training accuracy, val_accuracy - test (validation) accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tcFZGmfknKW4"
   },
   "source": [
    "### Wyświetlenie statystyk treningu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yqJT5EzGnT6O"
   },
   "outputs": [],
   "source": [
    "# strata\n",
    "plt.plot(r.history['loss'], label='loss')\n",
    "plt.plot(r.history['val_loss'], label='val_loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gJn4CMRInZqn"
   },
   "outputs": [],
   "source": [
    "# dokładność\n",
    "plt.plot(r.history['accuracy'], label='acc')\n",
    "plt.plot(r.history['val_accuracy'], label='val_acc')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iGe_GogRogGx"
   },
   "source": [
    "### Macierz błędu (ang. confusion matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l5DukvnGoiQR"
   },
   "outputs": [],
   "source": [
    "# Popatrzmy jeszcze na macierz błędu i zobaczmy z jakimi przykładami\n",
    "# sieć sobie nie poradziła.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(\n",
    "    cm,\n",
    "    classes,\n",
    "    normalize=False,\n",
    "    title='Confusion matrix',\n",
    "    cmap=plt.cm.Blues\n",
    "):\n",
    "  \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`\n",
    "  \"\"\"\n",
    "\n",
    "  if normalize:\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    print(\"Normalized confusion matrix\")\n",
    "  else:\n",
    "    print(\"Confusion matrix, without normalization\")\n",
    "\n",
    "  print(cm)\n",
    "\n",
    "  plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "  plt.title(title)\n",
    "  plt.colorbar()\n",
    "  tick_marks = np.arange(len(classes))\n",
    "  plt.xticks(tick_marks, classes, rotation=45)\n",
    "  plt.yticks(tick_marks, classes)\n",
    "\n",
    "  fmt = '.2f' if normalize else 'd'\n",
    "  thresh = cm.max() / 2.\n",
    "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.ylabel('True label')\n",
    "  plt.xlabel('Predicted label')\n",
    "  plt.show()\n",
    "\n",
    "p_test = model.predict(x_test).argmax(axis=1)\n",
    "cm = confusion_matrix(y_test, p_test)\n",
    "plot_confusion_matrix(cm, list(range(10)))\n",
    "\n",
    "# 9 <--> 4, 9 <--> 7, 2 <--> 7, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eQfuxoUMoxO7"
   },
   "outputs": [],
   "source": [
    "# Wyświetlmy kilka nieprawidłowo zaklasyfikowanych obrazów\n",
    "misclassified_idx = np.where(p_test != y_test)[0]\n",
    "i = np.random.choice(misclassified_idx)\n",
    "plt.imshow(x_test[i], cmap='gray')\n",
    "plt.title(f\"True label: {y_test[i]} Predicted: {p_test[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e7yFKixzsmWD"
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir './{log_dir}'"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "tf2.0 - Keras.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
